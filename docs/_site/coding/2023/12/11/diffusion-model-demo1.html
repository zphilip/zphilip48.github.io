<!DOCTYPE html>
<html lang="en-us">

<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  
  <!-- include collecttags -->
  
  





  

  <title>
    
      Diffusion Models Tutorial &middot; Zhu Philip's AI Journey
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link href="https://fonts.googleapis.com/css?family=East+Sea+Dokdo&display=swap" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.0/css/all.min.css" rel="stylesheet">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- merge something else -->
  
  <!-- merge something else 
  <link rel="stylesheet" href="/assets/css/post.css" />
  <link rel="stylesheet" href="/assets/css/syntax.css" /> -->
  
  
  <link rel="stylesheet" href="/assets/css/common.css" />
  <script src="/assets/js/categories.js"></script>  
  
  <script defer src="/assets/js/lbox.js"></script>
   

  <!-- MathJax -->
  <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  // Autonumbering by mathjax
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script> 

</head>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-89141653-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-89141653-4');
</script>



  <body>

    <link rel="stylesheet" href="/assets/style-3.css">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <div align="center">
          <img src="/assets/profile-pixel.png" class="profilepic pt-3 pb-2">
        </div>
        <!-- <a href="/"> -->
          Zhu Philip's AI Journey
        </a>
      </h1>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>

      <!-- Manual set order -->
      <a class="sidebar-nav-item" href="/categories">Categories</a>
      <a class="sidebar-nav-item" href="/working">Working</a>
      <a class="sidebar-nav-item" href="/publication">Publication</a>
      <a class="sidebar-nav-item" href="/cv">cv</a>
      <!-- <a class="sidebar-nav-item" href="/projects">Projects</a> -->
      <a class="sidebar-nav-item" href="/about">About</a>

      <!-- Uncomment for auto order -->
      <!-- 

      
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
          
        
      
        
      
        
          
        
      
        
      
        
          
            <a class="sidebar-nav-item" href="/categories/">Categories</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/cv/">CV</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/publication/">publications</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/working/">Working</a>
          
        
      
        
          
        
      
        
      
        
          
        
      
        
          
        
       -->

      
      <!-- <a class="sidebar-nav-item" href="https://github.com/zphilip/zphilip.github.io">GitHub project</a> -->
      <!-- <span class="sidebar-nav-item">Currently v</span> -->
      
<div id="social-media">
    
    
        
        
            <a href="mailto:zphilip48@gmail.com" title="Email"><i class="fa fa-envelope"></i></a>
        
    
        
        
            <a href="https://www.linkedin.com/in/tianda-zhu-37a5b031" title="Linkedin"><i class="fab fa-linkedin"></i></a>
        
    
        
        
            <a href="https://github.com/zphilip" title="GitHub"><i class="fab fa-github"></i></a>
        
    
        
        
            <a href="https://www.youtube.com/user/zphilip" title="YouTube"><i class="fab fa-youtube"></i></a>
        
    
</div>


    </nav>

    <p>&copy; 2024. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">Diffusion Models Tutorial</h1>
  <span class="post-date">11 Dec 2023</span>
  <p><a href="https://colab.research.google.com/github/azad-academy/denoising-diffusion-model/blob/main/diffusion_model_demo.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></p>

<h1 id="diffusion-models-tutorial">Diffusion Models Tutorial</h1>

<h4 id="author--j-rafid-siddiqui-jrsazaditechcom">Author : J. Rafid Siddiqui (jrs@azaditech.com)</h4>

<h2 id="loading-data">Loading Data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.font_manager</span>
<span class="c1">#font_manager._rebuild()
</span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="p">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s">"matplotlib.font_manager"</span><span class="p">).</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="p">.</span><span class="n">ERROR</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">hdr_plot_style</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">'dark_background'</span><span class="p">)</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">.</span><span class="n">update</span><span class="p">({</span><span class="s">'font.size'</span><span class="p">:</span> <span class="mi">18</span><span class="p">,</span> <span class="s">'lines.linewidth'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s">'lines.markersize'</span><span class="p">:</span> <span class="mi">15</span><span class="p">})</span>
    <span class="c1"># avoid type 3 (i.e. bitmap) fonts in figures
</span>    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'ps.useafm'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'pdf.use14corefonts'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'text.usetex'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'font.family'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'sans-serif'</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'font.sans-serif'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'Courier New'</span>
    <span class="c1"># mpl.rcParams['text.hinting'] = False
</span>    <span class="c1"># Set colors cycle
</span>    <span class="n">colors</span> <span class="o">=</span> <span class="n">mpl</span><span class="p">.</span><span class="n">cycler</span><span class="p">(</span><span class="s">'color'</span><span class="p">,</span> <span class="p">[</span><span class="s">'#3388BB'</span><span class="p">,</span> <span class="s">'#EE6666'</span><span class="p">,</span> <span class="s">'#9988DD'</span><span class="p">,</span> <span class="s">'#EECC55'</span><span class="p">,</span> <span class="s">'#88BB44'</span><span class="p">,</span> <span class="s">'#FFBBBB'</span><span class="p">])</span>
    <span class="c1">#plt.rc('figure', facecolor='#00000000', edgecolor='black')
</span>    <span class="c1">#plt.rc('axes', facecolor='#FFFFFF88', edgecolor='white', axisbelow=True, grid=True, prop_cycle=colors)
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'legend'</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s">'#666666EE'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'grid'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'solid'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'xtick'</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s">'out'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'ytick'</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s">'out'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'patch'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'#E6E6E6'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_checkerboard</span><span class="p">,</span><span class="n">make_circles</span><span class="p">,</span><span class="n">make_moons</span><span class="p">,</span><span class="n">make_s_curve</span><span class="p">,</span><span class="n">make_swiss_roll</span>
<span class="c1">#from helper_plot import hdr_plot_style
</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="c1">#from utils import * 
</span>
<span class="n">hdr_plot_style</span><span class="p">()</span>
<span class="n">swiss_roll</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_swiss_roll</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">,</span><span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">swiss_roll</span> <span class="o">=</span> <span class="n">swiss_roll</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span><span class="o">/</span><span class="mf">10.0</span>

<span class="n">s_curve</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span> <span class="n">make_s_curve</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">s_curve</span> <span class="o">=</span> <span class="n">s_curve</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span><span class="o">/</span><span class="mf">10.0</span>

<span class="n">moons</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">s_curve</span><span class="p">.</span><span class="n">T</span>
<span class="c1">#dataset = torch.Tensor(data.T).float()
</span>

<span class="n">fig</span><span class="p">,</span><span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">swiss_roll</span><span class="p">.</span><span class="n">T</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="c1">#dataset = torch.Tensor(data.T).float()
</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">moons</span><span class="p">.</span><span class="n">T</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">T</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_4_0.png" alt="png" /></p>

<h2 id="diffusion-models">Diffusion Models</h2>

<p><img src="images/diffusion.png" alt="diffusion-image" /></p>

<h3 id="forward-diffusion">Forward Diffusion</h3>

\[q(\mathbf{x}_{t}\mid\mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_{t} ; \sqrt{1-\beta_{t}}\mathbf{x}_{t-1},\beta_{t}\mathbf{I})\]

<p>Substituting $\alpha_{t}=1-\beta_{t}$ and $\bar{\alpha}<em>{t} = \prod</em>{s=1}^{t} \alpha_{s}$:</p>

\[q(\mathbf{x}_{t}\mid\mathbf{x}_{0}) = \mathcal{N}(\mathbf{x}_{t} ; \sqrt{\bar{\alpha}_{t}}\mathbf{x}_{t-1},(1-\bar{\alpha}_{t})\mathbf{I})\]

<p>Given the initial state, this makes it possible to draw sample at any desrired timestep without going through intermediate steps. Forward diffusion can also be written in terms of $x_0$ and the random noise $\epsilon \sim \mathcal{N}(0,1)$ [1]. This would be useful when performing denoising step later in the reverse diffusion.</p>

\[x_t(x_0,\epsilon) = \sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0} + \sqrt{1-\bar{\alpha_{t}}}\epsilon\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">make_beta_schedule</span><span class="p">(</span><span class="n">schedule</span><span class="o">=</span><span class="s">'linear'</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">schedule</span> <span class="o">==</span> <span class="s">'linear'</span><span class="p">:</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">schedule</span> <span class="o">==</span> <span class="s">"quad"</span><span class="p">:</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">end</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">elif</span> <span class="n">schedule</span> <span class="o">==</span> <span class="s">"sigmoid"</span><span class="p">:</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">)</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">betas</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">+</span> <span class="n">start</span>
    <span class="k">return</span> <span class="n">betas</span>

<span class="k">def</span> <span class="nf">extract</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="nb">input</span><span class="p">.</span><span class="n">device</span><span class="p">))</span>
    <span class="n">reshape</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">reshape</span><span class="p">)</span>    
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_steps</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1">#betas = torch.tensor([1.7e-5] * num_steps)
</span><span class="n">betas</span> <span class="o">=</span> <span class="n">make_beta_schedule</span><span class="p">(</span><span class="n">schedule</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="o">=</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mf">0.5e-2</span><span class="p">)</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">betas</span>
<span class="n">alphas_prod</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">alphas_prod_p</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]).</span><span class="nb">float</span><span class="p">(),</span> <span class="n">alphas_prod</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">alphas_bar_sqrt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">one_minus_alphas_bar_log</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">one_minus_alphas_bar_sqrt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
</code></pre></div></div>

<p>Following code which do the step by step add noise seems not necessary , due to the result donâ€™t use at all in training, the useful cacluation above is done.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">q_x</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">noise</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
    <span class="n">alphas_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">alphas_1_m_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">alphas_t</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">alphas_1_m_t</span> <span class="o">*</span> <span class="n">noise</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">q_i</span> <span class="o">=</span> <span class="n">q_x</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">i</span> <span class="o">*</span> <span class="mi">10</span><span class="p">]))</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="n">q_i</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">q_i</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_axis_off</span><span class="p">();</span> <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'$q(\mathbf{x}_{'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span><span class="o">+</span><span class="s">'})$'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_12_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">posterior_mean_coef_1</span> <span class="o">=</span> <span class="p">(</span><span class="n">betas</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">))</span>
<span class="n">posterior_mean_coef_2</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">))</span>
<span class="n">posterior_variance</span> <span class="o">=</span> <span class="n">betas</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">posterior_log_variance_clipped</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">posterior_variance</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">posterior_variance</span><span class="p">[</span><span class="mi">1</span><span class="p">:].</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="mi">0</span><span class="p">)).</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">q_posterior_mean_variance</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">coef_1</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_mean_coef_1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">coef_2</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_mean_coef_2</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">coef_1</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">coef_2</span> <span class="o">*</span> <span class="n">x_t</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_log_variance_clipped</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span>
</code></pre></div></div>

<h2 id="reverse-diffusionreconstruction">Reverse Diffusion/Reconstruction</h2>

<p>Unlike the forward diffusion, the reverse diffusion process requires training of a neural network model. We setup the necessary loss functions and training parameters and then perform the training.</p>

<h2 id="training">Training</h2>

<h3 id="training-loss">Training Loss</h3>

<p>The original loss was proposed in Sohl-Dickstein et al. [1] as following:</p>

<p>\begin{align}
K = -\mathbb{E}<em>{q}[ &amp;D</em>{KL}(q(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t},\mathbf{x}<em>{0}) \Vert p</em>{\theta}(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t}))  <br />
&amp;+ H_{q}(\mathbf{X}<em>{T}\vert\mathbf{X}</em>{0}) - H_{q}(\mathbf{X}<em>{1}\vert\mathbf{X}</em>{0}) - H_{p}(\mathbf{X}_{T})]
\end{align}</p>

<p>In order to improve the results, the authors in Ho et al. [2] proposed multiple improvements. Following Parameterization of mean is proposed:</p>

\[\mathbf{\mu}_{\theta}(\mathbf{x}_{t}, t) = \frac{1}{\sqrt{\alpha_{t}}} \left( (\mathbf{x}_{t} - \frac{\beta_{t}}{\sqrt{1 - \bar{\alpha}}_{t}} \mathbf{\epsilon}_{\theta} (\mathbf{x}_{t}, t) \right)\]

<p>further, variance is taken as constant and the step for reverse diffusion then becomes:</p>

\[\mathbf{x}_{t-1} = \frac{1}{\sqrt{\alpha_{t}}} \left( \mathbf{x}_{t} - \frac{1-\alpha_{t}}{\sqrt{1-\bar{\alpha_{t}}}} \mathbf{\epsilon}_{\theta}(\mathbf{x}_{t}, t) \right) + \sigma_{t}\mathbf{z}\]

<p>After further improvements and simplifications the loss function becomes:</p>

\[\mathcal{L}_{\text{simple}}=\mathbb{E}_{t, \mathbf{x}_{0},\mathbf{\epsilon}}\left[ \Vert \epsilon - \epsilon_{\theta}(\sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0} + \sqrt{1 - \bar{\alpha}_{t}}\mathbf{\epsilon}, t) \Vert^{2} \right].\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">p_sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">t</span><span class="p">])</span>
    <span class="c1"># Factor to the model output
</span>    <span class="n">eps_factor</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
    <span class="c1"># Model output
</span>    <span class="n">eps_theta</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="c1"># Final values
</span>    <span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">).</span><span class="n">sqrt</span><span class="p">())</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="p">(</span><span class="n">eps_factor</span> <span class="o">*</span> <span class="n">eps_theta</span><span class="p">))</span>
    <span class="c1"># Generate z
</span>    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Fixed sigma
</span>    <span class="n">sigma_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">).</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">sigma_t</span> <span class="o">*</span> <span class="n">z</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">sample</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">p_sample_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span><span class="n">n_steps</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">):</span>
    <span class="n">cur_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">x_seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">cur_x</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)):</span>
        <span class="n">cur_x</span> <span class="o">=</span> <span class="n">p_sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">cur_x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">)</span>
        <span class="n">x_seq</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_seq</span>
<span class="k">def</span> <span class="nf">noise_estimation_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span><span class="n">n_steps</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x_0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># Select a random step for each example
</span>    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,))</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">t</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">-</span> <span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[:</span><span class="n">batch_size</span><span class="p">].</span><span class="nb">long</span><span class="p">()</span>
    <span class="c1"># x0 multiplier
</span>    <span class="n">a</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="c1"># eps multiplier
</span>    <span class="n">am1</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
    <span class="c1"># model input
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">x_0</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">e</span> <span class="o">*</span> <span class="n">am1</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">e</span> <span class="o">-</span> <span class="n">output</span><span class="p">).</span><span class="n">square</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>    

<span class="c1">#An Implementation of Diffusion Network Model
#Oringinal source: https://github.com/acids-ircam/diffusion_models
</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">ConditionalLinear</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_in</span><span class="p">,</span> <span class="n">num_out</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConditionalLinear</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_out</span> <span class="o">=</span> <span class="n">num_out</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_in</span><span class="p">,</span> <span class="n">num_out</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">num_out</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embed</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">uniform_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embed</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_out</span><span class="p">)</span> <span class="o">*</span> <span class="n">out</span>
        <span class="k">return</span> <span class="n">out</span>
        
<span class="k">class</span> <span class="nc">ConditionalModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConditionalModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin1</span> <span class="o">=</span> <span class="n">ConditionalLinear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin2</span> <span class="o">=</span> <span class="n">ConditionalLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin3</span> <span class="o">=</span> <span class="n">ConditionalLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin4</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lin1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lin2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lin3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">lin4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#from model import ConditionalModel
</span><span class="kn">from</span> <span class="nn">ema</span> <span class="kn">import</span> <span class="n">EMA</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ConditionalModel</span><span class="p">(</span><span class="n">num_steps</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="c1">#dataset = torch.tensor(data.T).float()
# Create EMA model
</span><span class="n">ema</span> <span class="o">=</span> <span class="n">EMA</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">ema</span><span class="p">.</span><span class="n">register</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="c1"># Batch size
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># X is a torch Variable
</span>    <span class="n">permutation</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="c1"># Retrieve current batch
</span>        <span class="n">indices</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">batch_x</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="c1"># Compute the loss.
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">noise_estimation_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_x</span><span class="p">,</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span><span class="n">num_steps</span><span class="p">)</span>
        <span class="c1"># Before the backward pass, zero all of the network gradients
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># Backward pass: compute gradient of the loss with respect to parameters
</span>        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># Perform gradient clipping
</span>        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.</span><span class="p">)</span>
        <span class="c1"># Calling the step function to update the parameters
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># Update the exponential moving average
</span>        <span class="n">ema</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="c1"># Print loss
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">x_seq</span> <span class="o">=</span> <span class="n">p_sample_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">num_steps</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">)</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
            <span class="n">cur_x</span> <span class="o">=</span> <span class="n">x_seq</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">10</span><span class="p">].</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">set_axis_off</span><span class="p">();</span> 
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'$q(\mathbf{x}_{'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="o">+</span><span class="s">'})$'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor(0.9140, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.6532, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.6371, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.8389, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.6238, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.5684, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.8178, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.7874, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.7548, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.8650, grad_fn=&lt;MeanBackward0&gt;)
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_1.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_2.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_3.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_4.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_5.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_6.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_7.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_8.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_9.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_10.png" alt="png" /></p>

<h2 id="animation">Animation</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generating the forward image sequence
</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">imgs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1">#fig, axs = plt.subplots(1, 10, figsize=(28, 3))
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">clf</span><span class="p">()</span>
    <span class="n">q_i</span> <span class="o">=</span> <span class="n">q_x</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">q_i</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">q_i</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">);</span> 
    
    <span class="n">img_buf</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">img_buf</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">'png'</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">img_buf</span><span class="p">)</span>
    <span class="n">imgs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_23_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generating the reverse diffusion sequence
</span>
<span class="n">reverse</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>  
    <span class="n">plt</span><span class="p">.</span><span class="n">clf</span><span class="p">()</span>
    <span class="n">cur_x</span> <span class="o">=</span> <span class="n">x_seq</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
    
    <span class="n">img_buf</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">img_buf</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">'png'</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">img_buf</span><span class="p">)</span>
    <span class="n">reverse</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_24_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imgs</span> <span class="o">=</span> <span class="n">imgs</span> <span class="o">+</span> <span class="n">reverse</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imgs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">save</span><span class="p">(</span><span class="s">"diffusion.gif"</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">'GIF'</span><span class="p">,</span> <span class="n">append_images</span><span class="o">=</span><span class="n">imgs</span><span class="p">,</span><span class="n">save_all</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">loop</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="references">References</h1>

<p>[1] Ho, J., Jain, A., &amp; Abbeel, P. (2020). Denoising diffusion probabilistic models. arXiv preprint arXiv:2006.11239.</p>

<p>[2] Sohl-Dickstein, J., Weiss, E. A., Maheswaranathan, N., &amp; Ganguli, S. (2015). Deep unsupervised learning using nonequilibrium thermodynamics. arXiv preprint arXiv:1503.03585.</p>

</div>

<span class="post-tags">
    
      <i class="fa fa-tag fa-xs" aria-hidden="true"></i>
      
      <a class="no-underline" href="/tag/AI"><nobr>AI</nobr></code>&nbsp;</a>    
    
      <i class="fa fa-tag fa-xs" aria-hidden="true"></i>
      
      <a class="no-underline" href="/tag/Diffusion"><nobr>Diffusion</nobr></code>&nbsp;</a>    
    
</span>

<div class="recent">
  <h2>Recent Posts</h2>
  <ul class="recent-posts">
    
      <li>
        <h4>
          <a href="/coding/2023/12/11/diffusion-model-demo2.html">
            A Diffusion Model from Scratch in Pytorch
          </a>
          <small>[11 Dec 2023]</small>
        </h4>
      </li>
    
      <li>
        <h4>
          <a href="/coding/2023/12/02/transformer-implementation.html">
            transformer implementation
          </a>
          <small>[02 Dec 2023]</small>
        </h4>
      </li>
    
      <li>
        <h4>
          <a href="/coding/2023/12/02/Inspect-BERT-Vocabulary.html">
            Inspect BERT Vocabulary
          </a>
          <small>[02 Dec 2023]</small>
        </h4>
      </li>
    
  </ul>
</div>
    </div>

  </body>
</html>
