---
layout: page
title:  "working todo"
date:   2024-03-25
categories: working
tags: AI
---

- [x] #task compare the nougat small model and code with the nougat big model what's the different between them.  ğŸ”¼ ğŸ›« 2024-01-09 : âœ… 2024-01-21
- transformer version change to  4.34.1, then it work (static saving safe is in newer version)
- [x] #task based work output of above task let's partially loading the Chinese Bart pre-trained model data ğŸ”¼ ğŸ›« 2024-01-09 âœ… 2024-02-29
- [x] prepare one small set dataset include Chinese data for training ğŸ”¼ ğŸ›« 2024-01-09 âœ… 2024-01-21
- small set dataset --- nougat-dataset-test include - ocrpadded, ocrset
- Done. the original bart model ("facebook/mbart-large-50") already has multiple language support include chinese Bart pre-trained ,
-  languages covered
Arabic (ar_AR), Czech (cs_CZ), German (de_DE), English (en_XX), Spanish (es_XX), Estonian (et_EE), Finnish (fi_FI), French (fr_XX), Gujarati (gu_IN), Hindi (hi_IN), Italian (it_IT), Japanese (ja_XX), Kazakh (kk_KZ), Korean (ko_KR), Lithuanian (lt_LT), Latvian (lv_LV), Burmese (my_MM), Nepali (ne_NP), Dutch (nl_XX), Romanian (ro_RO), Russian (ru_RU), Sinhala (si_LK), Turkish (tr_TR), Vietnamese (vi_VN), Chinese (zh_CN), Afrikaans (af_ZA), Azerbaijani (az_AZ), Bengali (bn_IN), Persian (fa_IR), Hebrew (he_IL), Croatian (hr_HR), Indonesian (id_ID), Georgian (ka_GE), Khmer (km_KH), Macedonian (mk_MK), Malayalam (ml_IN), Mongolian (mn_MN), Marathi (mr_IN), Polish (pl_PL), Pashto (ps_AF), Portuguese (pt_XX), Swedish (sv_SE), Swahili (sw_KE), Tamil (ta_IN), Telugu (te_IN), Thai (th_TH), Tagalog (tl_XX), Ukrainian (uk_UA), Urdu (ur_PK), Xhosa (xh_ZA), Galician (gl_ES), Slovene (sl_SI)

The loading such as :  ==MBartForCausalLM.from_pretrained( "facebook/mbart-large-50" ).state_dict()==
- [ ] adding authentication function to android and pc side client. let's start this after Chinese supporting in server side.
- [ ] adding authentication and security function to server side (multiple user supporting). let's start this after Chinese supporting in server side. 
- [x] today's work ğŸ“… 2024-01-11 , â«  try to modify the ocr padding method to scale the ocr png to size fit  swin-transformer , then padding.  I suspect the training error is caused by too small png ğŸ›« padding.  current size is 672(w)x896(h)x8.. arxiv size is 816x1056x24.. something wrong. âœ… 2024-02-29
- notice that the original code has the resize function to make the small picture to fit the 886*672 size , so using the original un-padding figure (latex ocr dataset image) to feed the current training. but still have the "repetition error"
- ==(DONE) put the original un-padding figure  and the padded figure together into the training== , it seems that the training have no "repetition error" still unclear why it is so????
	- this have the repetition error... while using bigger dataset from arXiv orignal data
	- I am think the VIT how to train the all blank image... it is lead to some error , or how it is treated , get some test ???
	- how about using all back or white image as training data 
	- how the voice to text treat the white noise? how the blank image is treated 
	- in normal ViT , the fixed size image is always required...,   how about reserve the SWIN transformer architecture, change from low level resolution to high resolution 
	- #todo Need to check the result after above change....
- [x] bleu score âœ… 2024-01-12, the bleu score is noted at [[Transformer_learning#3.2 Bleu Score]]
- [x] Pytorch-viewçš„ç”¨æ³• âœ… 2024-02-29
- åœ¨pytorchä¸­viewå‡½æ•°çš„ä½œç”¨ä¸ºé‡æ„å¼ é‡çš„ç»´åº¦ï¼Œç›¸å½“äºnumpyä¸­resizeï¼ˆï¼‰çš„åŠŸèƒ½ï¼Œä½†æ˜¯ç”¨æ³•å¯èƒ½ä¸å¤ªä¸€æ ·ã€‚å¦‚ä¸‹ä¾‹æ‰€ç¤º

```text
>>> import torch
>>> tt1=torch.tensor([-0.3623, -0.6115,  0.7283,  0.4699,  2.3261,  0.1599])
>>> result=tt1.view(3,2)
>>> result
tensor([[-0.3623, -0.6115],
        [ 0.7283,  0.4699],
        [ 2.3261,  0.1599]])
```

1. torch.view(å‚æ•°aï¼Œå‚æ•°bï¼Œ...)

åœ¨ä¸Šé¢ä¾‹å­ä¸­å‚æ•°a=3å’Œå‚æ•°b=2å†³å®šäº†å°†ä¸€ç»´çš„tt1é‡æ„æˆ3x2ç»´çš„å¼ é‡ã€‚

2. æœ‰çš„æ—¶å€™ä¼šå‡ºç°torch.view(-1)æˆ–è€…torch.view(å‚æ•°aï¼Œ-1)è¿™ç§æƒ…å†µã€‚
```text
>>> import torch
>>> tt2=torch.tensor([[-0.3623, -0.6115],
...         [ 0.7283,  0.4699],
...         [ 2.3261,  0.1599]])
>>> result=tt2.view(-1)
>>> result
tensor([-0.3623, -0.6115,  0.7283,  0.4699,  2.3261,  0.1599])
```
ç”±ä¸Šé¢çš„æ¡ˆä¾‹å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœæ˜¯torch.view(-1)ï¼Œåˆ™åŸå¼ é‡ä¼šå˜æˆä¸€ç»´çš„ç»“æ„ã€‚
```text
>>> import torch
>>> tt3=torch.tensor([[-0.3623, -0.6115],
...         [ 0.7283,  0.4699],
...         [ 2.3261,  0.1599]])
>>> result=tt3.view(2,-1)
>>> result
tensor([[-0.3623, -0.6115,  0.7283],
        [ 0.4699,  2.3261,  0.1599]])
```

ç”±ä¸Šé¢çš„æ¡ˆä¾‹å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœæ˜¯torch.view(å‚æ•°aï¼Œ-1)ï¼Œåˆ™è¡¨ç¤ºåœ¨å‚æ•°bæœªçŸ¥ï¼Œå‚æ•°aå·²çŸ¥çš„æƒ…å†µä¸‹è‡ªåŠ¨è¡¥é½åˆ—å‘é‡é•¿åº¦ï¼Œåœ¨è¿™ä¸ªä¾‹å­ä¸­a=2ï¼Œtt3æ€»å…±ç”±6ä¸ªå…ƒç´ ï¼Œåˆ™b=6/2=3ã€‚


**Albumentationsæ•°æ®å¢å¼ºæ–¹æ³• **, practice in notebook "/labs/nougat_unet/predict.ipynb", refer page [Albumentationsæ•°æ®å¢å¼ºæ–¹æ³•_shiftscalerotate-CSDNåšå®¢](https://blog.csdn.net/qq_27039891/article/details/100795846)

- [x] Long Table splitting into small one âœ… 2024-03-07
- almost done with , extract_table/saveHtmlFile/split_row function in crawler__dataset_generate.py .  this function split the html table into different small table.   
- the problem is if the table have multiple figure embedded,  the size of the html is not controlled well
- table size is not good way to estimate.  current only calculate the text/word count 
- [ ] Text emotion /sentiment split, text to voice model study...etc
	- [x] checked the Text emotion and text voice internet resources âœ… 2024-03-07
	- [ ] next to setup one local text to voice model to test 

# Daily Work Notes 2024-03-07
1, in last few days , I try to setup [fofr/cog-face-to-sticker: face-to-sticker (github.com)](https://github.com/fofr/cog-face-to-sticker) in my local machine. it is one model/workflow with ComfyUI --- No successe yet.  It is maybe the memeory issue. I will continue to do this and the final goal is integarated with my website and give some trail.

2, in last few days, I try to combine the FastAPI and gradio together for my AIWorm.cn/Nougat+ website.  some problem goging. 

3, learning content of today :  
- [x] #task PCA [Principal Component Analysis (PCA) (youtube.com)](https://www.youtube.com/watch?v=fkf4IBRSeEc&list=WL&index=111)
- [ ] #task Setup ğŸ›« 2024-03-07 face-to-sticker

# Daily Work Notes 2024-03-08
1, continue doing docker maker for nougat webserver which starting from yesterday
2, continue learning PCA 
3, Start the nougat learning note to record the all result, following is the nougat middle model using partially arxiv data and some Chinese internet data crawlered 
![[W&B Chart 2024_3_8 09_20_34.png]]
![[W&B Chart 2024_3_8 09_20_54.png]]
This is the previous small model training loss figure. every Time stop training and restart from checkpoint, you will see the loss is high.. unsure why?

![[W&B Chart 2024_3_4 16_21_15 1.png]]
Previous Vit+unet transformer test result
![[W&B Chart 2024_3_8 09_32_58.png]]

## nested regex expression note: 
exampleï¼š[regex101: build, test, and debug regex](https://regex101.com/r/NsVPFp/3) 
`\(+\*+  (?:[^*(]|(?:\*+[^)*])|(?:\(+[^*(]))*     \*+\)+`
	`/\(+\*+ (?:(?:`
	        `\(+\*+    (?:(?:`
	        
	                   `\(+\*+       (?:[ ^*(  ]  |  (?  :\*+[^)*]  )  |  (?:\(+[^*(])   )*`
	
	                   `\*+\)+        )|[^*(]|(?:\*+[^)*])|(?:\(+[^*(]))*`
	
	        `\*+\)+    )|[^*(]|(?:\*+[^)*])|(?:\(+[^*(]))*`
	 
	`\*+\)+`
[regex - Regular expressions for pattern matching time format in python - Stack Overflow](https://stackoverflow.com/questions/62584721/regular-expressions-for-pattern-matching-time-format-in-python)
### nested regex expression :
`p{1} = \{  (?:[^{}])*   \}`
`p{2} = \{  (?:   (?:   p{1}   ) |  (?:[^{}])  )*   \}`
[regex101: build, test, and debug regex](https://regex101.com/r/JewQGp/1/) https://regex101.com/r/4liwhI/1

`\{  (?:(?:`   
     `\{    (?:(?:`   
           `\{    (?:[^{}])*`    
               `\}   )|(?:[^{}]))*`   
                    `\}    )|(?:[^{}]))*`   
                          `\}`
- replace with (\\begin{([a-z]+?\*?)}) to the \{  so we have following
	`p{1} = (?<!\\)(\\begin{([a-z]+?\*?)})(?:(?!\\begin{\2}|\\end{\2}).)*(\\end{\2})`
	
	`(?:[^{}])* ---- (?:(?!\\begin{\2}|\\end{\2}).)*`  exclude structure æ’é™¤ç»“æ„ , for example `(?<!\\|\$)(\$)([^\$]+)(\$)(?:(?![$|\\]).)`
	https://regex101.com/r/yngAW3/1
	`p{2} = (?<!\\)(\\begin{([a-z]+?\*?)})(?:(?:(?<!\\)(\\begin{([a-z]+?\*?)})(?:(?!\\begin{\2}|\\end{\2}).)*(\\end{\2}))|(?:(?!\\begin{\2}|\\end{\2}).)*)*(\\end{\2})`
	
	`p{3} = (?<!\\)(\\begin{([a-z]+?\*?)})(?:(?:(?<!\\)(\\begin{([a-z]+?\*?)})(?:(?:(?<!\\)(\\begin{([a-z]+?\*?)})(?:(?!\\begin{\2}|\\end{\2}).)*(\\end{\2}))|(?:(?!\\begin{\2}|\\end{\2}).)*)*(\\end{\2}))|(?:(?!\\begin{\2}|\\end{\2}).)*)*(\\end{\2})`
- final version 
	`"(?<!\\)(\\begin{([a-z]+?\*?)})(?:(?:(?<!\\)(\\begin{([a-z]+?\*?)})(?:(?:(?<!\\)(\\begin{([a-z]+?\*?)})(?:(?!\\begin{\6}|\\end{\6}).)*(\\end{\6}))|(?:(?!\\begin{\4}|\\end{\4}).))*(\\end{\4}))|(?:(?!\\begin{\2}|\\end{\2}).))*(\\end{\2})"gm`
	https://regex101.com/r/7zJ0g1/1

	`(?:[ ^*(  ]  |  (?  :\*+[^)*]  )  |  (?:\(+[^*(])   )*`
	`(?:[ ^{}                                        ]   )*`
	`(?:[^(\\begin{([a-z]+?\*?)})+(\\end{\2})+])*`
	
	`)|    [^*(] | (?:\*+[^)*])   |  (?:\(+[^*(])         )*`
	`)|    (?: [^{}])                                   )*`
	`)|    (?: [^ (\\begin{([a-z]+?\*?)})+(\\end{\2})+]) )*`
	
	`(\\begin{([a-z]+?\*?)})+   (?:(?:`
	    `(\\begin{([a-z]+?\*?)})+     (?:(?:`
	            `(\\begin{([a-z]+?\*?)})+     (?:[^*(]|(?:\*+[^)*])|(?:\(+[^*(]))*`
	                     `(\\end{\2})+            )|[^*(]|(?:\*+[^)*])|(?:\(+[^*(]))*`
	                              `(\\end{\2})+       )|[^*(]|(?:\*+[^)*])|(?:\(+[^*(]))*`
	                                      `(\\end{\2})+`
	
	
	                                      `(?:[^{\1}]|(?:\*+[^(\\end{\2})+])|(?:\(+[^{\1}]))*`
	
	                                      `(\\begin{([a-z]+?\*?)})[^(\\end)](.+?)(\\end{\2})(.+?)(\\end{\2})+`
	
	
	
	                                      `(\\begin{([a-z]+?\*?)})+(?:(?:(\\begin{([a-z]+?\*?)})+(?:(?:(\\begin{([a-z]+?\*?)})+(?:[^(\\begin{\2})(\\end{\2})]|(?:\*+[^(\\end{\2})])|(?:\(+[^(\\begin{\2})]))*(\\end{\2})+)[^(\\begin{\2})(\\end{\2})]|(?:\*+[^(\\end{\2})])|(?:\(+[^(\\begin{\2})]))*(\\end{\2})+)[^(\\begin{\2})^(\\end{\2})]|(?:\*+[^(\\end{\2})])|(?:\(+[^(\\begin{\2})]))*(\\end{\2})+`
	
	`(\\begin{([a-z]+?\*?)})(?:[^(\\begin{\2})]|(?:\*+[^(\\end{\2})])|(?:\(+[^(\\begin{\2})]))*(\\end{\2})`                                    
	  `^(?!(red|green|blue)$).*$`
  
  ## hard-disk mount by uuid
	`/dev/sdd        /data/data1     ext4    defaults        0       0`
	`/dev/sdc        /data/data2     ext4    defaults        0       0`
	`/dev/sdb        /data/data3     ext4    defaults        0       0`
		
	`lrwxrwxrwx 1 root root 10 Jan 10 06:24 39e64f6f-4e8d-4f78-93bc-59179f553043 -> ../../sda2`
	`lrwxrwxrwx 1 root root 10 Jan 10 06:24 3a6a811a-10b0-4e56-8675-f6266f6db518 -> ../../dm-0`
	`lrwxrwxrwx 1 root root  9 Jan 10 06:24 799f8d5f-e372-465c-b5a9-aa42db0cee36 -> ../../sdb`
	`lrwxrwxrwx 1 root root  9 Jan 10 06:24 7b800e22-10f5-4b8a-96ca-856b8a77fdb6 -> ../../sdd`
	`lrwxrwxrwx 1 root root  9 Jan 10 06:24 d0e23ef0-ae13-4277-8671-340b4a0fb934 -> ../../sdc`
	
	`scsi-1ATA_INTEL_SSDSC2BB800G6R_BTWA641100TT800HGN -> ../../sda`
	
	`ata-INTEL_SSDSC2BB800G6R_BTWA641100TT800HGN -> ../../sda`
	`ata-TOSHIBA_HDWE160_971UK1WTF56D -> ../../sdd`
	`ata-TOSHIBA_MD04ACA500_55E8K1SFFS9A -> ../../sdc`
	`ata-WDC_WUS721010ALE6L4_VCK8940P -> ../../sdb`
	
	`(base) userroot@userroot:~$ blkid`
	`/dev/sda2: UUID="39e64f6f-4e8d-4f78-93bc-59179f553043" TYPE="ext4" PARTUUID="28c6cfbd-5edc-4e53-8342-b76c1f91dd50"`
	`/dev/sda3: UUID="7dNYf8-rzin-MHJB-895r-HQWt-pL5c-A3tedU" TYPE="LVM2_member" PARTUUID="257300e4-a1fa-4512-bf9b-963d5e4292bc"`
	`/dev/sdc: UUID="d0e23ef0-ae13-4277-8671-340b4a0fb934" TYPE="ext4"`
	`/dev/sdd: UUID="7b800e22-10f5-4b8a-96ca-856b8a77fdb6" TYPE="ext4"`
	`/dev/sdb: UUID="799f8d5f-e372-465c-b5a9-aa42db0cee36" TYPE="ext4"`
	`/dev/mapper/ubuntu--vg-ubuntu--lv: UUID="3a6a811a-10b0-4e56-8675-f6266f6db518" TYPE="ext4"`
	- fstab:
	`UUID=7b800e22-10f5-4b8a-96ca-856b8a77fdb6        /data/data1     ext4    defaults        0       0`
	`UUID=d0e23ef0-ae13-4277-8671-340b4a0fb934        /data/data2     ext4    defaults        0       0`
	`UUID=799f8d5f-e372-465c-b5a9-aa42db0cee36        /data/data3     ext4    defaults        0       0`

# Daily Work Notes 2024-03-11
1. try to rebuild the comfyui's environment/and try cog docker build , the problem might be the environment issue
2. continue the work task "aiworm.cn websit setup" 
3. continue the learning task "pca"

# Daily Work Notes 2024-03-13
1. still failed to setup the face to sticker comfyui environment... this time using the windows comfyui 
2. aiworm.cn websit work onging , almost done.... the problem now for those model accuracy is not enough.   more bigger model? beside this, while using the Chinese and English mixed text , it will translate part of it, it is not what wanted....  it need to dig out
- [ ] mBart or Bert model stopping translate but just inference in nougat task
3. PCA/SVD continue.  
4. stop training in the AutoDL in Epoch 17 ... I will add new code to separate the Chinese and English text in tokenizer... it might be some mistaken I don't found out before :
 BERTå¤šè¯­è¨€ç‰ˆæœ¬é¢„è®­ç»ƒæ¨¡å‹ä¸Šçº¿å‰éœ€è¦å¯¹å¥å­è¿›è¡Œäººå·¥åˆ†å­—
![](/assets/obsidian_assets/Pasted image 20240313095711.png)

```
def trans(sen):
    """
    Translates a sentence containing both Chinese and English characters.
    If a word is in Chinese, it adds the word and its translation.
    Otherwise, it keeps the word unchanged.
    """
    buf = ""
    for word in sen:
        if "\u4e00" <= word <= "\u9fff":
            buf += f'{word} ' + "translation of Chinese character"
        else:
            buf += word
    return buf.replace(' ', ',')

if __name__ == "__main__":
    chline = "åŒ…å«ä¸­æ–‡å­—ç¬¦çš„å¥å­ã€‚"
    enline = 'The use of citations in evaluative scientometrics as a proxy for quality'

    chenline = "åŒ…å«è‹±æ–‡Theï¼ŒåŒ…å«ä¸­æ–‡ use ofåŒ…å«è‹±æ–‡citations in evaluative scientometrics as a proxy for quality"
    print(trans(chline))
    print(trans(enline))
    print(trans(chenline))
```

# Daily Work Notes 2024-03-17
![Pasted image 20240318093438.png](/assets/obsidian_assets/Pasted image 20240318093438.png)
# Daily Work Notes 2024-03-25
<img src="/assets/obsidian_assets/Pasted image 20240325101352.png" alt="img" style="zoom: 100%;" />

1. task PCA  learning is finished. the note should be published to blog
2. [ ] publish PCA learning note to blog
3. [ ] start to prepare the article about the nougat/OCR structure improvement
4. finish the improvements about upload file and at same time give parameters to fastapi. 
	1. [python - How to POST both Files and a List of JSON data in FastAPI? - Stack Overflow](https://stackoverflow.com/questions/77254763/how-to-post-both-files-and-a-list-of-json-data-in-fastapi/77279612#77279612)
	2. [python - How to add both file and JSON body in a FastAPI POST request? - Stack Overflow](https://stackoverflow.com/questions/65504438/how-to-add-both-file-and-json-body-in-a-fastapi-post-request)
	3. current using simple way as following: 

```
## Method 1

As describedÂ [here](https://fastapi.tiangolo.com/tutorial/request-forms-and-files/), one can define files and form fileds at the same time usingÂ `File`Â andÂ `Form`. Below is a working example. In case you had a large number of parameters and would like toÂ **define them separately from the endpoint**, please have a look atÂ [this answer](https://stackoverflow.com/a/71650857/17865804)Â on how to create a custom dependency class instead.

**app.py**
	from fastapi import Form, File, UploadFile, Request, FastAPI
	from typing import List
	from fastapi.responses import HTMLResponse
	from fastapi.templating import Jinja2Templates
	
	app = FastAPI()
	templates = Jinja2Templates(directory="templates")
	
	
	@app.post("/submit")
	def submit(
	    name: str = Form(...),
	    point: float = Form(...),
	    is_accepted: bool = Form(...),
	    files: List[UploadFile] = File(...),
	):
	    return {
	        "JSON Payload": {"name": name, "point": point, "is_accepted": is_accepted},
	        "Filenames": [file.filename for file in files],
	    }
	
	
	@app.get("/", response_class=HTMLResponse)
	def main(request: Request):
	    return templates.TemplateResponse("index.html", {"request": request})

test.py:
	import requests
	url = 'http://127.0.0.1:8000/submit'
	files = [('files', open('test_files/a.txt', 'rb')), ('files', open('test_files/b.txt', 'rb'))]
	data = {"name": "foo", "point": 0.13, "is_accepted": False}
	resp = requests.post(url=url, data=data, files=files) 
	print(resp.json())
```

1. start to fastAPI authentication/user data to database???? 
	- save user data
	- security